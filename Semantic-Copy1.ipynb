{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import tifffile\n",
    "import gdal\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tifffile import imsave\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.42-cp37-cp37m-win_amd64.whl (33.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\miniconda\\envs\\tensorflow\\lib\\site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.42\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=gdal.Open(r'C:\\Users\\rrkot\\Desktop\\T33_mod_Cnv\\T3\\T33_mod.bin.bin')\n",
    "fn_array=fn.ReadAsArray()\n",
    "imsave('T33mod.tif',fn_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9473,  8960,  8952, ..., 11960, 16146, 12617],\n",
       "       [ 9258,  7438,  7437, ..., 14140, 17572, 12490],\n",
       "       [ 9181,  7313,  7424, ..., 14759, 17856, 13360],\n",
       "       ...,\n",
       "       [ 9010,  7383,  7416, ..., 14015, 12861, 12312],\n",
       "       [ 8992,  7442,  7376, ..., 11990,  9738, 10330],\n",
       "       [ 9424,  9443,  9287, ..., 11856, 10288,  8121]], dtype=uint16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_array.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "def inflate_my_image():\n",
    "    dir_path=r'D:\\Semantic\\Unet\\Open THis\\unet SUkri\\data\\train\\image'\n",
    "    num_images=len(os.listdir(dir_path))\n",
    "    print(num_images)\n",
    "    for i in range(1,num_images+1):\n",
    "        pic_array=tifffile.imread(dir_path+'{}.tif'.format(i))\n",
    "        \n",
    "        \n",
    "inflate_my_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260, 1328)\n",
      "(2260, 1328, 1)\n",
      "(2260, 1328, 3)\n"
     ]
    }
   ],
   "source": [
    "r=r'D:\\GeoSpatial\\Data\\Mumbai\\T3\\Tiff\\Mumbai'\n",
    "q=tifffile.imread(r+'\\T{}.tif'.format(11))\n",
    "qbar=np.shape(q)\n",
    "print(qbar)\n",
    "w=q[:,:,np.newaxis]\n",
    "print(np.shape(w))\n",
    "#wbar=np.concatenate(q,np.zeros((512,512,1)),axis=2)\n",
    "wbar=np.dstack((w,w))\n",
    "wbar=np.dstack((wbar,w))\n",
    "print(np.shape(wbar))\n",
    "u=tifffile.imsave('trial.tif',wbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.03142229, 0.03142229, 0.03142229],\n",
       "         [0.04544418, 0.04544418, 0.04544418],\n",
       "         [0.04613599, 0.04613599, 0.04613599],\n",
       "         ...,\n",
       "         [0.03820745, 0.03820745, 0.03820745],\n",
       "         [0.03373365, 0.03373365, 0.03373365],\n",
       "         [0.03244915, 0.03244915, 0.03244915]],\n",
       " \n",
       "        [[0.03771712, 0.03771712, 0.03771712],\n",
       "         [0.07845586, 0.07845586, 0.07845586],\n",
       "         [0.07499295, 0.07499295, 0.07499295],\n",
       "         ...,\n",
       "         [0.07096207, 0.07096207, 0.07096207],\n",
       "         [0.06255542, 0.06255542, 0.06255542],\n",
       "         [0.06255542, 0.06255542, 0.06255542]],\n",
       " \n",
       "        [[0.03993776, 0.03993776, 0.03993776],\n",
       "         [0.07899097, 0.07899097, 0.07899097],\n",
       "         [0.07810053, 0.07810053, 0.07810053],\n",
       "         ...,\n",
       "         [0.05293619, 0.05293619, 0.05293619],\n",
       "         [0.05034767, 0.05034767, 0.05034767],\n",
       "         [0.05523838, 0.05523838, 0.05523838]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.04690054, 0.04690054, 0.04690054],\n",
       "         [0.08812839, 0.08812839, 0.08812839],\n",
       "         [0.08917335, 0.08917335, 0.08917335],\n",
       "         ...,\n",
       "         [0.07490692, 0.07490692, 0.07490692],\n",
       "         [0.07490692, 0.07490692, 0.07490692],\n",
       "         [0.07372653, 0.07372653, 0.07372653]],\n",
       " \n",
       "        [[0.05206264, 0.05206264, 0.05206264],\n",
       "         [0.09432545, 0.09432545, 0.09432545],\n",
       "         [0.09393553, 0.09393553, 0.09393553],\n",
       "         ...,\n",
       "         [0.07640394, 0.07640394, 0.07640394],\n",
       "         [0.07683392, 0.07683392, 0.07683392],\n",
       "         [0.07552615, 0.07552615, 0.07552615]],\n",
       " \n",
       "        [[0.0521115 , 0.0521115 , 0.0521115 ],\n",
       "         [0.09294635, 0.09294635, 0.09294635],\n",
       "         [0.09051043, 0.09051043, 0.09051043],\n",
       "         ...,\n",
       "         [0.08252644, 0.08252644, 0.08252644],\n",
       "         [0.07867207, 0.07867207, 0.07867207],\n",
       "         [0.07447898, 0.07447898, 0.07447898]]], dtype=float32),\n",
       " array([[0.03142229, 0.04544418, 0.04613599, ..., 0.03820745, 0.03373365,\n",
       "         0.03244915],\n",
       "        [0.03771712, 0.07845586, 0.07499295, ..., 0.07096207, 0.06255542,\n",
       "         0.06255542],\n",
       "        [0.03993776, 0.07899097, 0.07810053, ..., 0.05293619, 0.05034767,\n",
       "         0.05523838],\n",
       "        ...,\n",
       "        [0.04690054, 0.08812839, 0.08917335, ..., 0.07490692, 0.07490692,\n",
       "         0.07372653],\n",
       "        [0.05206264, 0.09432545, 0.09393553, ..., 0.07640394, 0.07683392,\n",
       "         0.07552615],\n",
       "        [0.0521115 , 0.09294635, 0.09051043, ..., 0.08252644, 0.07867207,\n",
       "         0.07447898]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbar,q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch(img):\n",
    "    return np.dsplit(img,img.shape[-1])\n",
    "[a,b,c]=ch(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range (1,16):\n",
    "    wbar=tifffile.imread('{}.tif'.format(l))\n",
    "    np.shape(wbar)\n",
    "    q=wbar.transpose(0,1,2)\n",
    "    [a,b,c]=ch(q)\n",
    "    tifffile.imsave(\"{}.tif\".format(l),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imsave('1.tif',a)\n",
    "#tifffile.imsave('2.tif',d)\n",
    "#tifffile.imsave('3.tif',g)\n",
    "#tifffile.imsave('4.tif',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "comp1=b==g\n",
    "comp2=b==r\n",
    "comp3=g==r\n",
    "eq1=comp1.all()\n",
    "eq2=comp2.all()\n",
    "eq3=comp3.all()\n",
    "print(eq1)\n",
    "print(eq2)\n",
    "print(eq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(name):\n",
    "    img=tifffile.imread(name)\n",
    "    #img=cv2.imread(name)\n",
    "    #imgo=img.asarray(img)\n",
    "    imgi=Image.fromarray(img)\n",
    "   \n",
    "    return imgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(imag,Partition_no):\n",
    "    for num in range(Partition_no):          #My image was of dimension 1328x2260\n",
    "        \n",
    "        if (num==1):\n",
    "            cropped=imag.crop((0,0,512,512)) #Enter Pixel range.(topleft,upper,bottomright,lower)\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('1.tif',convert_array)\n",
    "            print(\"First done\")\n",
    "        elif (num==3):\n",
    "            cropped=imag.crop((816,0,1328,512))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('2.tif',convert_array)\n",
    "            print(\"Third done\")\n",
    "        elif (num==2):\n",
    "            cropped=imag.crop((513,0,1025,512))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('3.tif',convert_array)\n",
    "            print(\"Second done\")\n",
    "        elif (num==4):\n",
    "            cropped=imag.crop((0,512,512,1024))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('4.tif',convert_array)\n",
    "            print(\"Fourth done\")\n",
    "        elif(num==5):\n",
    "            cropped=imag.crop((513,512,1025,1024))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('5.tif',convert_array)\n",
    "            print(\"Fifth done\")\n",
    "        elif (num==6):\n",
    "            cropped=imag.crop((816,512,1328,1024))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('6.tif',convert_array)\n",
    "            print(\"Sixth done\")\n",
    "        elif (num==7):\n",
    "            cropped=imag.crop((0,1024,512,1536))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('7.tif',convert_array)\n",
    "            print(\"Seventh done\")\n",
    "        elif (num==8):\n",
    "            cropped=imag.crop((513,1024,1025,1536))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('8.tif',convert_array)\n",
    "            print(\"Eighth done\")\n",
    "        elif (num==9):\n",
    "            cropped=imag.crop((816,1024,1328,1536))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('9.tif',convert_array)\n",
    "            print('Ninth done')\n",
    "        elif(num==10):\n",
    "            cropped=imag.crop((0,1536,512,2048))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('10.tif',convert_array)\n",
    "            print('Tenth done')\n",
    "        elif(num==11):\n",
    "            cropped=imag.crop((513,1536,1025,2048))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('11.tif',convert_array)\n",
    "            print(\"Eleventh done\")\n",
    "        elif(num==12):\n",
    "            cropped=imag.crop((816,1536,1328,2048))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('12.tif',convert_array)\n",
    "            print(\"Twelth done\")\n",
    "        elif(num==13):\n",
    "            cropped=imag.crop((0,1748,512,2260))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('13.tif',convert_array)\n",
    "            print(\"Thirteenth done\")\n",
    "        elif(num==14):\n",
    "            cropped=imag.crop((513,1748,1025,2260))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('14.tif',convert_array)\n",
    "            print(\"Fourteenth done\")\n",
    "        elif(num==15):\n",
    "            cropped=imag.crop((816,1748,1328,2260))\n",
    "            convert_array=np.array(cropped)\n",
    "            imsave('15.tif',convert_array)\n",
    "            print(\"Fifteenth done\")\n",
    "        else:\n",
    "            print(\"Starting up engine\")\n",
    "\n",
    "    return print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260, 1328)\n"
     ]
    }
   ],
   "source": [
    "test= load_image(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\UINT16R\\T33.tif')\n",
    "print(np.shape(test))\n",
    "test\n",
    "Partition_no=16  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up engine\n",
      "First done\n",
      "Second done\n",
      "Third done\n",
      "Fourth done\n",
      "Fifth done\n",
      "Sixth done\n",
      "Seventh done\n",
      "Eighth done\n",
      "Ninth done\n",
      "Tenth done\n",
      "Eleventh done\n",
      "Twelth done\n",
      "Thirteenth done\n",
      "Fourteenth done\n",
      "Fifteenth done\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "crop_img(test,Partition_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2260, 1328)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puta=tifffile.imread(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\Tiff\\Mumbai\\Mumbai.tif')\n",
    "np.shape(puta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00369877, 0.00360754, 0.00382666, ..., 0.04737408, 0.04976995,\n",
       "        0.04841785],\n",
       "       [0.00452759, 0.00773904, 0.00788792, ..., 0.09341532, 0.11644132,\n",
       "        0.06513959],\n",
       "       [0.00452347, 0.00830301, 0.00773714, ..., 0.11094887, 0.12427004,\n",
       "        0.06086783],\n",
       "       ...,\n",
       "       [0.00433374, 0.0084161 , 0.008103  , ..., 0.05622543, 0.05882409,\n",
       "        0.03152891],\n",
       "       [0.00429615, 0.00830512, 0.00828467, ..., 0.05616434, 0.05778513,\n",
       "        0.03504248],\n",
       "       [0.0040924 , 0.00487128, 0.00471039, ..., 0.03181709, 0.03906632,\n",
       "        0.03720917]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Make an 8-bit version for display\n",
    "(Image.fromarray((puta*200).astype(np.float32)).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n",
      "(8, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for z in range(1,16):    \n",
    "    a=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T11\\{}.tif'.format(z))\n",
    "    b=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T12mod\\{}.tif'.format(z))\n",
    "    c=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T13mod\\{}.tif'.format(z))\n",
    "    d=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T22\\{}.tif'.format(z))\n",
    "    e=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T23mod\\{}.tif'.format(z))\n",
    "    f=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T22\\{}.tif'.format(z))\n",
    "    g=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T23mod\\{}.tif'.format(z))\n",
    "    h=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T33\\{}.tif'.format(z))\n",
    "    #i=tifffile.imread(r'D:\\miniconda\\envs\\tensorflow\\Notebook\\T33\\{}.tif'.format(z))\n",
    "    #w=q[:,:,np.newaxis]\n",
    "    #t=qbar[:,:,np.newaxis]\n",
    "    wbar=np.dstack((a,b))\n",
    "    wbar=np.dstack((wbar,c))\n",
    "    wbar=np.dstack((wbar,d))\n",
    "    wbar=np.dstack((wbar,e))\n",
    "    wbar=np.dstack((wbar,f))\n",
    "    wbar=np.dstack((wbar,g))\n",
    "    wbar=np.dstack((wbar,h))\n",
    "    #wbar=np.dstack((wbar,i))\n",
    "    #wbar=np.dstack((wbar,w))\n",
    "    o=wbar.transpose([2,0,1])\n",
    "    print(np.shape(o))\n",
    "    u=tifffile.imsave('{}.tif'.format(z),o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a TIFF file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg, name, offset, size, multifile, movie, **kwargs)\u001b[0m\n\u001b[0;32m   1751\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1752\u001b[1;33m                 \u001b[0mbyteorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34mb'II'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'MM'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1753\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: b'BM'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-33460b0e45eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtifffile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\PauliRGB.bmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(files, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seek'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mTiffFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg, name, offset, size, multifile, movie, **kwargs)\u001b[0m\n\u001b[0;32m   1752\u001b[0m                 \u001b[0mbyteorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34mb'II'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'MM'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1754\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'not a TIFF file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1755\u001b[0m             \u001b[0msys_byteorder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'big'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'little'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'<'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbyteorder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msys_byteorder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not a TIFF file"
     ]
    }
   ],
   "source": [
    "x=tifffile.imread(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\Tiff\\Labels\\image.tif')\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(image_path, saved_location):\n",
    "    \"\"\"\n",
    "    Flip or mirror the image\n",
    "    @param image_path: The path to the image to edit\n",
    "    @param saved_location: Path to save the cropped image\n",
    "    \"\"\"\n",
    "    image_obj = Image.open(image_path)\n",
    "    rotated_image = image_obj.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    rotated_image=rotated_image.rotate(180)\n",
    "    #print(type(rotated_image))\n",
    "    rotated_image.save(saved_location)\n",
    "    #rotated_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "image = (r'D:\\miniconda\\envs\\tensorflow\\Notebook\\UINT16\\T33mod.tif')\n",
    "flip_image(image, 'T33mod.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci=Image.open(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\PauliRGB.bmp')\n",
    "rc=ci.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "rc.show()\n",
    "rc.save('PauliRGB.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=tifffile.imread(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\Tiff\\Mumbai\\Stacked\\Mumbai.tif')\n",
    "img2=tifffile.imread(r'D:\\Dataset\\Traintestsplit\\train\\label\\13.tif')\n",
    "img3=tifffile.imread(r'C:\\Users\\rrkot\\Desktop\\test1.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3=img3.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 512, 3), (512, 512, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(img2),np.shape(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]]], dtype=uint8),\n",
       " array([[[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204]],\n",
       " \n",
       "        [[ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         ...,\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204],\n",
       "         [ 63,  72, 204]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]],\n",
       " \n",
       "        [[255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]],\n",
       " \n",
       "        [[255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         [255, 127,  39],\n",
       "         ...,\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36],\n",
       "         [236,  28,  36]]], dtype=uint8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2,img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 1D or 2D array, got 3D array instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7448b741cd2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#np.savetxt(\"truth.csv\", img2, delimiter=\",\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pred.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1393\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1395\u001b[1;33m                 \"Expected 1D or 2D array, got %dD array instead\" % X.ndim)\n\u001b[0m\u001b[0;32m   1396\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m             \u001b[1;31m# Common case -- 1d array of numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 1D or 2D array, got 3D array instead"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"truth.csv\", img2, delimiter=\",\")\n",
    "np.savetxt(\"pred.csv\", img3, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8574f06e3d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[1;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unknown is not supported"
     ]
    }
   ],
   "source": [
    "multilabel_confusion_matrix(img2,img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=tifffile.imread(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\UINT16R\\T23img.tif')\n",
    "img2=tifffile.imread(r'D:\\Dataset\\GeoSpatial\\Data\\Mumbai\\T3\\Tiff\\Mumbai\\Stacked\\Mumbai.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30979, 31072, 31032, ..., 29664, 26358, 18986],\n",
       "       [30955, 30903, 30603, ..., 22527, 32113, 37515],\n",
       "       [30965, 30705, 30655, ..., 24779, 38325, 37238],\n",
       "       ...,\n",
       "       [30412, 30432, 30634, ..., 28881, 34245, 32254],\n",
       "       [30370, 30271, 30629, ..., 37168, 31421, 25657],\n",
       "       [30451, 30627, 30608, ..., 38618, 38264, 21966]], dtype=uint16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65535"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-131.65527"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2144.0564"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x must have 2 or fewer dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3adf848b1ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[0;32m   2608\u001b[0m         \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2609\u001b[0m         color=color, label=label, stacked=stacked, **({\"data\": data}\n\u001b[1;32m-> 2610\u001b[1;33m         if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[0;32m   6578\u001b[0m         \u001b[0minput_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6579\u001b[0m         \u001b[1;31m# Massage 'x' for processing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6580\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape_2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6581\u001b[0m         \u001b[0mnx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# number of datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_reshape_2D\u001b[1;34m(X, name)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} must have 2 or fewer dimensions\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x must have 2 or fewer dimensions"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(img1,bins='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
